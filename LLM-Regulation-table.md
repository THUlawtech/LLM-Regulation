|Name|Type|Country/Region|Date|å‘æ–‡å•ä½|source|Risks|Risk Perspective|çˆ¶è®°å½•|
|---|---|---|---|---|---|---|---|---|
|[Interim Measures for the Administration of Generative Artificial Intelligence Services](PDFs/ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡ç®¡ç†æš‚è¡ŒåŠæ³•.pdf)|Laws and Regulations - Effect|ğŸ‡¨ğŸ‡³ China|2023-08-15 00:00:00|The CAC and other six department|[link](https://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)|3,2,14|AI é£é™©æ¥æº|nan|
|[Practice Guidelines for Cybersecurity Standards - Identification Methods for Contents of Generative Artificial Intelligence Services](PDFs/ç½‘ç»œå®‰å…¨æ ‡å‡†å®è·µæŒ‡å—â€”â€”ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡å†…å®¹æ ‡è¯†æ–¹æ³•.pdf)|Standards/Guidelines|ğŸ‡¨ğŸ‡³ China|2024-08-25 00:00:00|TC260|[link](https://www.tc260.org.cn/front/postDetail.html?id=20230825190345)|14|AI é£é™©æ¥æº|nan|
|[TC260 - 003 Basic Security Requirements for Generative Artificial Intelligence Service](PDFs/TC260-003_ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æœåŠ¡å®‰å…¨åŸºæœ¬è¦æ±‚.pdf)|Standards/Guidelines|ğŸ‡¨ğŸ‡³ China|2024-03-01 00:00:00|TC260|[link](https://www.tc260.org.cn/front/postDetail.html?id=20240301164054)|4,3,13,11,17,2|AI é£é™©æ¥æº, AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Artificial intelligenceâ€”Code of practice for data labeling of machine learning](PDFs/GB_T_42755-2023_äººå·¥æ™ºèƒ½_é¢å‘æœºå™¨å­¦ä¹ çš„æ•°æ®æ ‡æ³¨è§„ç¨‹.pdf)|Standards/Guidelines|ğŸ‡¨ğŸ‡³ China|2023-12-01 00:00:00|TC28|[link](https://std.samr.gov.cn/gb/search/gbDetailed?id=FC816D04FEB462EBE05397BE0A0AD5FA)|3|AI é£é™©æ¥æº|nan|
|[harmonised rules and regulations on artificial intelligence](PDFs/Artificial_Intelligence_Act.pdf) |Laws and Regulations - Effect|ğŸ‡ªğŸ‡º EU|2024-06-13 00:00:00|EU|[link](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)|11|AI é£é™©æ¥æº|nan|
|[Cyber security risks to artificial intelligence](PDFs/Cyber_security_risks_to_artificial_intelligence.pdf)|Research Reports|ğŸ‡¬ğŸ‡§ UK|2024-05-15 00:00:00|Department for Science, Innovation &Technology|[link](https://www.gov.uk/government/publications/research-on-the-cyber-security-of-ai/cyber-security-risks-to-artificial-intelligence#methodology)|8, 17|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[OWASP Top 10 for LLM Applications 2025](PDFs/OWASP_Top_10_for_LLM_Applications_2025.pdf)|Research Reports|ğŸŒ International Organizations|2024-11-18 00:00:00|OWASP|[link](https://owasp.org/www-project-top-10-for-large-language-model-applications/)|5,8,3,17,12,14|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Machine learning security principles v2](PDFs/Machine_learning_security_principles_v2.pdf)|Research Reports|ğŸ‡¬ğŸ‡§ UK|2024-05-22 00:00:00|NCSC|[link](https://www.ncsc.gov.uk/blog-post/machine-learning-security-principles-updated)|8,17,9,13|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Guidelines for Secure AI System Development](PDFs/Guidelines_for_Secure_AI_System_Development.pdf)|Standards/Guidelines|ğŸŒ Multiple Countries|2023-11-26 00:00:00|USA CISA, UK NCSC, the Australian Signals Directorateâ€™s Australian Cyber Security Centre (ASD ACSC), the Canadian Centre for Cyber Security (CCCS), the New Zealand National Cyber Security Centre (NCSC-NZ)|[link](https://www.cisa.gov/news-events/alerts/2023/11/26/cisa-and-uk-ncsc-unveil-joint-guidelines-secure-ai-system-development)|17|AI é£é™©æ¥æº|nan|
|[Secure Software Development Practices for Generative AI and Dual-Use Foundation Models: An SSDF Community Profile](PDFs/Secure_Software_Development_Practices_for_Generative_AI_and_Dual-Use_Foundation_Models_An_SSDF_Community_Profile.pdf)|Standards/Guidelines|ğŸ‡ºğŸ‡¸ USA|2024-07-26 00:00:00|NIST|[link](https://csrc.nist.gov/pubs/sp/800/218/a/final)|9,8,17|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile](PDFs/Artificial_Intelligence_Risk_Management_Framework_Generative_Artificial_Intelligence_Profile.pdf)|Standards/Guidelines|ğŸ‡ºğŸ‡¸ USA|2024-07-26 00:00:00|NIST|[link](https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence)|11,1,2,4,15|AI é£é™©æ¥æº|nan|
|[Artificial Intelligence Risk Management Framework (AI RMF 1.0)](PDFs/Artificial_Intelligence_Risk_Management_Framework(AI_RMF_1_0).pdf)|Standards/Guidelines|ğŸ‡ºğŸ‡¸ USA|2023-01-26 00:00:00|NIST|[link](https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-ai-rmf-10)|4,6,8,12,13|AI é£é™©æ¥æº, AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Reducing Risks Posed by Synthetic Content](PDFs/Reducing_Risks_Posed_by_Synthetic_Content.pdf)|Standards/Guidelines|ğŸ‡ºğŸ‡¸ USA|2024-11-24 00:00:00|NIST|[link](https://www.nist.gov/publications/reducing-risks-posed-synthetic-content-overview-technical-approaches-digital-content)|14,15,3|AI é£é™©æ¥æº|nan|
|[LLM AI Cybersecurity & Governance Checklist](PDFs/LLM_AI_Cybersecurity&Governance_Checklist.pdf)|Research Reports|ğŸŒ International Organizations|2024-02-19 00:00:00|OWASP|[link](https://owasp.org/www-project-top-10-for-large-language-model-applications/llm-top-10-governance-doc/LLM_AI_Security_and_Governance_Checklist-v1.pdf)|2,5|AI é£é™©æ¥æº|nan|
|[The Bletchley Declaration](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023)|Forums and Conferences|ğŸŒ Multiple Countries|2024-11-01 00:00:00|AI Safety Summit 2023|[link](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration)|9,14|AI é£é™©æ¥æº|nan|
|[Consensus Statement on Red Lines in Artificial Intelligence](https://idais-beijing.baai.ac.cn/?lang=zh)|Forums and Conferences|ğŸŒ Multiple Countries|2024-03-10 00:00:00|â€œBeijing AI Security International Dialogueâ€ Forum|[link](https://idais-beijing.baai.ac.cn/?lang=zh)|9,14,8|AI é£é™©æ¥æº|nan|
|[Hiroshima Process International Guiding Principles for Advanced AI system](PDFs/Hiroshima_Process_International_Guiding_Principles_for_Advanced_AI_system.pdf)|Standards/Guidelines|ğŸŒ Multiple Countries|2023-10-30 00:00:00|G7|[link](https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-principles-advanced-ai-system)|4,11,14|AI é£é™©æ¥æº|nan|
|[Hiroshima Process International Code of Conduct for Advanced AI Systems](PDFs/Hiroshima_Process_International_Code_of_Conduct_for_Advanced_AI_Systems.pdf)|Standards/Guidelines|ğŸŒ Multiple Countries|2023-10-30 00:00:00|G7|[link](https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-advanced-ai-systems)|1,2,12,14,8|AI é£é™©æ¥æº|nan|
|[Blueprint for an AI Bill of Right](PDFs/Blueprint_for_an_AI_Bill_of_Right.pdf)|Policy Documents|ğŸ‡ºğŸ‡¸ USA|2022-10-04 00:00:00|OSTP (Office of Science and Technology Policy)|[link](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)|7,4,11,2,12,6,13|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Joint Statement on Enforcement Efforts Against Discrimination and Bias in Automated Systems](PDFs/Joint_Statement_on_Enforcement_Efforts_Against_Discrimination_and_Bias_in_Automated_Systems.pdf)|Policy Documents|ğŸ‡ºğŸ‡¸ USA|2023-04-25 00:00:00|Consumer Financial Protection Bureau|[link](https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/joint-statement-enforcement-efforts-against-discrimination-bias-automated-systems)|2,4,7,12,14,6,13|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Quality Control Standards for Automated Valuation Models](PDFs/Quality_Control_Standards_for_Automated_Valuation_Models.pdf)|Standards/Guidelines|ğŸ‡ºğŸ‡¸ USA|2023-06-21 00:00:00|CFPB, OCC, FRB, FDIC, NCUA, and FHFA|[link](https://www.consumerfinance.gov/rules-policy/final-rules/quality-control-standards-for-automated-valuation-models/)|4,6,14,13|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Coloradoâ€™s Consumer Artificial Intelligence Act (SB 24-205)](PDFs/Coloradoâ€™s_Consumer_Artificial_Intelligence_Act(SB_24-205).pdf)|Laws and Regulations - Effect|ğŸ‡ºğŸ‡¸ USA|2024-05-17 00:00:00|Colorado|[link](https://leg.colorado.gov/bills/sb24-205)|4,7,6,5,2,12|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Safe and Secure Innovation for Frontier Artificial Intelligence Models Actï¼ˆCA SB 1047ï¼‰](PDFs/Safe_and_Secure_Innovation_for_Frontier_Artificial_Intelligence_Models_Act(CA_SB_1047).pdf)|Laws and Regulations - Drafted/Not Effect|ğŸ‡ºğŸ‡¸ USA|2024-09-03 00:00:00|California|[link](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)|9,10,8,17,18,5|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Digital Content Provenance Standards (CA AB 3211)](PDFs/Digital_Content_Provenance_Standards(CA_AB_3211).pdf)|Laws and Regulations - Effect|ğŸ‡ºğŸ‡¸ USA|2024-08-23 00:00:00|California|[link](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB3211)|4,14,17,3,6 |AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Artificial Intelligence Security Governance Framework v1](PDFs/äººå·¥æ™ºèƒ½å®‰å…¨æ²»ç†æ¡†æ¶v1.pdf)|Standards/Guidelines|ğŸ‡¨ğŸ‡³ China|2024-09-09 00:00:00|tc 260|[link](https://www.tc260.org.cn/front/postDetail.html?id=20240909102807)|1,2,3,6,4,9,5,16,17,14,12,11|AI åº”ç”¨åœºæ™¯, AI é£é™©æ¥æº, AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Seizing the Opportunities of Safe, Secure and Trustworthy Artificial Intelligence Systems for Sustainable Development](PDFs/Seizing_the_Opportunities_of_Safe,Secure_and_Trustworthy_Artificial_Intelligence_Systems_for_Sustainable_Development.pdf)|Policy Documents|ğŸŒ International Organizations|2024-03-21 00:00:00|UN|[link](https://digitallibrary.un.org/record/4043244/?v=pdf)|4,5,11,12,13,14,6,7,18,16|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[Guidelines on Securing AI Systems](PDFs/Guidelines_on_Securing_AI_Systems.pdf)|Standards/Guidelines|ğŸ‡¸ğŸ‡¬ Singapore|2024-10-15 00:00:00|CSA|[link](https://www.csa.gov.sg/Tips-Resource/publications/2024/guidelines-on-securing-ai)|1,2,4,6,7,8,9,12,14,15,16,17,18,13|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Companion Guide on Securing AI Systems](PDFs/companion_Guide_on_Securing_AI_Systems.pdf)|Standards/Guidelines|ğŸ‡¸ğŸ‡¬ Singapore|2024-10-15 00:00:00|CSA|[link](https://www.csa.gov.sg/Tips-Resource/publications/2024/guidelines-on-securing-ai)|nan|nan|Guidelines_on_Securing_AI_Systems|
|[ICO consultation series on generative AI and data protection](https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-series-on-generative-ai-and-data-protection/)|Research Reports|ğŸ‡¬ğŸ‡§ UK|2024-09-18 00:00:00|ICO|[link](https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-series-on-generative-ai-and-data-protection/)|12,11,13,5,6,7,2|AI é£é™©æ¥æº|nan|
|[Guidance on AI and data protection](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/)|Research Reports|ğŸ‡¬ğŸ‡§ UK|2023-03-15 00:00:00|ICO|[link](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/)|4,5,6,7,11,12,14,16,17,18,13|AI é£é™©æ¥æº, AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Discussion paper on GDPR and LLMs](PDFs/Discussion_paper_on_GDPR_and_LLMs.pdf)|Research Reports|ğŸ‡©ğŸ‡ª German|2024-07-15 00:00:00|HmbBfDI|[link](https://datenschutz-hamburg.de/news/hamburger-thesen-zum-personenbezug-in-large-language-models)|2,12,14,13|AI é£é™©æ¥æº|nan|
|[Checklist for the use of LLM-based chatbots](PDFs/Checklist_for_the_use_of_LLM-based_chatbots.pdf)|Standards/Guidelines|ğŸ‡©ğŸ‡ª German|2023-11-13 00:00:00|HmbBfDI|[link](https://datenschutz-hamburg.de/news/checkliste-zum-einsatz-llm-basierter-chatbots)|2,12,11,18,4,14,13|AI é£é™©æ¥æº|nan|
|[Opinion 28/2024 on certain data protection aspects related to the processing of personal data in the context of AI models](PDFs/Opinion_28_2024_on_certain_data_protection_aspects_related_to_the_processing_of_personal_data_in_the_context_of_AI_models.pdf)|Research Reports|ğŸ‡ªğŸ‡º EU|2024-10-28 00:00:00|EDPB|[link](https://www.edpb.europa.eu/our-work-tools/our-documents/opinion-board-art-64/opinion-282024-certain-data-protection-aspects_en)|2,5,7,8,11,14|AI é£é™©æ¥æº|nan|
|[The Artificial Intelligence and Data Act (AIDA)](PDFs/The_Artificial_Intelligence_and_Data_Act(AIDA).pdf)|Laws and Regulations - Drafted/Not Effect|ğŸ‡¨ğŸ‡¦ Canada|2022-06-16 00:00:00|Minister of Innovation, Science and Industry|[link](https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading)|2,4,7,8,11,12,14,18|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|nan|
|[The Artificial Intelligence and Data Act (AIDA)  â€“ Companion document](https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-companion-document)|Standards/Guidelines|ğŸ‡¨ğŸ‡¦ Canada|2023-03-13 00:00:00|Minister of Innovation, Science and Industry|[link](https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-companion-document)|2,4,7,8,11,12,14,18|AI ç”Ÿå‘½å‘¨æœŸ, AI é£é™©æ¥æº|The_Artificial_Intelligence_and_Data_Act(AIDA)|
|[Voluntary  Code of Conduct on the Responsible Development and Management of Advanced  Generative AI Systems](https://ised-isde.canada.ca/site/ised/en/voluntary-code-conduct-responsible-development-and-management-advanced-generative-ai-systems)|Standards/Guidelines|ğŸ‡¨ğŸ‡¦ Canada|2024-09-01 00:00:00|nan|[link](https://ised-isde.canada.ca/site/ised/en/voluntary-code-conduct-responsible-development-and-management-advanced-generative-ai-systems)|4,11,8,14,9,13|AI é£é™©æ¥æº|nan|
|[Australiaâ€™s AI Ethics Principles](https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles)|Standards/Guidelines|ğŸ‡¦ğŸ‡º Australia|2019-01-01 00:00:00|Department of Industry, Science and Resources|[link](https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles)|12,7,8,6,13|AI é£é™©æ¥æº|nan|
|[Safe and Responsible  AI in Australia (Discussion paper)](PDFs/Safe_and_Responsible_AI_in_Australia(Discussion_paper).pdf)|Research Reports|ğŸ‡¦ğŸ‡º Australia|2023-06-01 00:00:00|Department of Industry, Science and Resources|[link](https://consult.industry.gov.au/supporting-responsible-ai)|4,11,13,14,2|AI é£é™©æ¥æº|nan|
|[Safe and responsible Al in Australia consultation - Australian Government's interim response](PDFs/Safe_and_responsible_Al_in_Australia_consultation-Australian_Government_s_interim_response.pdf)|Research Reports|ğŸ‡¦ğŸ‡º Australia|2024-01-17 00:00:00|Department of Industry, Science and Resources|[link](https://consult.industry.gov.au/supporting-responsible-ai)|1,4,6,7,11,13,15|AI é£é™©æ¥æº|nan|
|[Select Committee on  Adopting Artificial Intelligence(PDFs/Select_Committee_on_Adopting_Artificial_Intelligence.pdf)]|Laws and Regulations - Effect|ğŸ‡¦ğŸ‡º Australia|2024-03-26 00:00:00|nan|[link](https://www.aph.gov.au/Parliamentary_Business/Committees/Senate/Adopting_Artificial_Intelligence_AI/AdoptingAI)|1,2,4,7,11,12,14,16,18|AI ç”Ÿå‘½å‘¨æœŸ, AI åº”ç”¨åœºæ™¯|nan|
|[National framework for the assurance of  artificial intelligence in government](PDFs/National_framework_for_the_assurance_of_artificial_intelligence_in_government.pdf)|Standards/Guidelines|ğŸ‡¦ğŸ‡º Australia|2024-06-21 00:00:00|Australian, state and territory governments|[link](https://www.finance.gov.au/sites/default/files/2024-06/National-framework-for-the-assurance-of-AI-in-government.pdf)|4,6,11,17,13|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[AI Guidelines for Business v1](PDFs/AI_Guidelines_for_Business_v1.pdf)|Standards/Guidelines|ğŸ‡¯ğŸ‡µ Japan|2024-04-19 00:00:00|METI, Ministry of Economy, Trade and Industry|[link](https://www.meti.go.jp/english/press/2024/0419_002.html)|1,2,4,7,11,18,14|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Methodology for the Risk and Impact Assessment of Artificial Intelligence Systems from the Point of View of Human Rights, Democracy and the Rule of Law (HUDERIA Methodology)](PDFs/Methodology_for_the_Risk_and_Impact_Assessment_of_Artificial_Intelligence_Systems_from_the_Point_of_View_of_Human_Rights,Democracy_and_the_Rule_of_Law(HUDERIA_Methodology).pdf)|Standards/Guidelines|ğŸ‡ªğŸ‡º EU|2024-09-28 00:00:00|CAI, Committee on Artificial Intelligence|[link](https://www.coe.int/en/web/artificial-intelligence/huderia-risk-and-impact-assessment-of-ai-systems)|4,6,11,14,13|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Open letter to UK online service providers regarding Generative AI and chatbots](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/open-letter-to-uk-online-service-providers-regarding-generative-ai-and-chatbots/)|Standards/Guidelines|ğŸ‡¬ğŸ‡§ UK|2024-11-08 00:00:00|OFCOM|[link](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/open-letter-to-uk-online-service-providers-regarding-generative-ai-and-chatbots/)|11,14|AI åº”ç”¨åœºæ™¯|nan|
|[Online Safety Act](https://www.legislation.gov.uk/ukpga/2023/50/contents/enacted)|Laws and Regulations - Effect|ğŸ‡¬ğŸ‡§ UK|2023-10-26 00:00:00|OFCOM|[link](https://www.legislation.gov.uk/ukpga/2023/50/section/1/enacted)|nan|nan|Open letter to UK online service providers regarding Generative AI and chatbots|
|[Introduction to AI Assurance](PDFs/Introduction_to_AI_Assurance.pdf)|Standards/Guidelines|ğŸ‡¬ğŸ‡§ UK|2024-02-12 00:00:00|DSIT, Department for Science, Innovation and Technology|[link](https://www.gov.uk/government/publications/introduction-to-ai-assurance)|4,7,11,12,2|AI ç”Ÿå‘½å‘¨æœŸ, AI åº”ç”¨åœºæ™¯|nan|
|[Guidance for using the AI Management Essentials tool](PDFs/Guidance_for_using_the_AI_Management_Essentials_tool.pdf)|Standards/Guidelines|ğŸ‡¬ğŸ‡§ UK|2024-11-06 00:00:00|DSIT|[link](https://www.gov.uk/government/consultations/ai-management-essentials-tool/guidance-for-using-the-ai-management-essentials-tool)|4,7,5,12,11,13|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[Compliance of products with embedded artificial intelligence](PDFs/Compliance_of_products_with_embedded_artificial_intelligence.pdf)|Standards/Guidelines|ğŸŒ International Organizations|2024-11-04 00:00:00|UNECE|[link](https://unece.org/trade/publications/ece_trade_486)|4,8,11,17,13|AI åº”ç”¨åœºæ™¯|nan|
|[Model AI Governance Framework for Generative AI](PDFs/Model_AI_Governance_Framework_for_Generative_AI.pdf)|Standards/Guidelines|ğŸ‡¸ğŸ‡¬ Singapore|2024-05-24 00:00:00|IMDA|[link](https://aiverifyfoundation.sg/resources/mgf-gen-ai/)|1,2,4,6,9,11,13,17|AI ç”Ÿå‘½å‘¨æœŸ|nan|
|[AI and cyber security: what you need to know](PDFs/AI_and_cyber_security_what_you_need_to_know.pdf)|Research Reports|ğŸ‡¬ğŸ‡§ UK|2024-02-13 00:00:00|NCSC|[link](https://www.ncsc.gov.uk/guidance/ai-and-cyber-security-what-you-need-to-know)|4,11,13,14|AI é£é™©æ¥æº|nan|
|[Machine learning principles](PDFs/Machine_learning_principles.pdf)|Standards/Guidelines|ğŸ‡¬ğŸ‡§ UK|2024-05-22 00:00:00|NCSC|[link](https://www.ncsc.gov.uk/collection/machine-learning-principles)|4,8,9,11,12,17,18|AI ç”Ÿå‘½å‘¨æœŸ|nan|
