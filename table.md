| Title                                                                                                                                                                         | type                 | Country/Region   | Date                | Organization                                                                                                                                                                                                 | source                                                                                                                                                                 | risks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | risk perspective                      |
|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------|:-----------------|:--------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------|
| Interim Measures for the Administration of Generative Artificial Intelligence Services of the People's Republic of China                                                      | 法律法规 - 已生效    | 🇨🇳 中国          | 2023-08-15 00:00:00 | 国家互联网信息办公室等七部门                                                                                                                                                                                 | [link](https://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)                                                                                                       | 3. 训练数据 - 数据标注, 2. 训练数据 - 违规收集 - 个人信息相关, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                                                                           | AI 风险来源                           |
| Practice Guidelines for Cybersecurity Standards - Identification Methods for Contents of Generative Artificial Intelligence Services                                          | 标准指南、技术性文件 | 🇨🇳 中国          | 2024-08-25 00:00:00 | TC260                                                                                                                                                                                                        | [link](https://www.tc260.org.cn/front/postDetail.html?id=20230825190345)                                                                                               | 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | AI 风险来源                           |
| TC260 - 003 Basic Security Requirements for Generative Artificial Intelligence Service                                                                                        | 标准指南、技术性文件 | 🇨🇳 中国          | 2024-03-01 00:00:00 | TC260                                                                                                                                                                                                        | [link](https://www.tc260.org.cn/front/postDetail.html?id=20240301164054)                                                                                               | 9. 模型 - 准确性、可靠性（幻觉）, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 3. 训练数据 - 数据标注, 14. 生成内容 - 模型幻觉, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 18. 供应链相关风险, 2. 训练数据 - 违规收集 - 个人信息相关                                                                                                                                                                                                                                                                            | AI 风险来源, AI 生命周期              |
| Artificial intelligence—Code of practice for data labeling of machine learning                                                                                                | 标准指南、技术性文件 | 🇨🇳 中国          | 2023-12-01 00:00:00 | TC28                                                                                                                                                                                                         | [link](https://std.samr.gov.cn/gb/search/gbDetailed?id=FC816D04FEB462EBE05397BE0A0AD5FA)                                                                               | 3. 训练数据 - 数据标注                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | AI 风险来源                           |
| harmonised rules and regulations on artificial intelligence                                                                                                                   | 法律法规 - 已生效    | 🇪🇺 欧盟          | 2024-06-13 00:00:00 | EU                                                                                                                                                                                                           | [link](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)                                                                                                                 | 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）                                                                                                                                                                                                                                                                                                                                                                                                                                                    | AI 风险来源                           |
| Cyber security risks to artificial intelligence                                                                                                                               | 研究报告             | 🇬🇧 英国          | 2024-05-15 00:00:00 | Department for                                                                                                                                                                                               | [link](https://www.gov.uk/government/publications/research-on-the-cyber-security-of-ai/cyber-security-risks-to-artificial-intelligence#methodology)                    | 8. 模型 - 鲁棒性、抗干扰性, 18. 供应链相关风险                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | AI 生命周期                           |
|                                                                                                                                                                               |                      |                  |                     | Science, Innovation                                                                                                                                                                                          |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
|                                                                                                                                                                               |                      |                  |                     | & Technology                                                                                                                                                                                                 |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| OWASP Top 10 for LLM Applications 2025                                                                                                                                        | 研究报告             | 🌍 NONE          | 2024-11-18 00:00:00 | OWASP                                                                                                                                                                                                        | [link](https://owasp.org/www-project-top-10-for-large-language-model-applications/)                                                                                    | 5. 训练数据 - 数据泄露, 8. 模型 - 鲁棒性、抗干扰性, 3. 训练数据 - 数据标注, 18. 供应链相关风险, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                 | AI 生命周期, AI 风险来源              |
|                                                                                                                                                                               |                      |                  |                     | （开放式 Web 应用程序安全项目，致力于 Web 应用程序安全的国际非营利组织）                                                                                                                                     |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| Machine learning security principles v2                                                                                                                                       | 研究报告             | 🇬🇧 英国          | 2024-05-22 00:00:00 | NCSC（英国国家网络安全中心）                                                                                                                                                                                 | [link](https://www.ncsc.gov.uk/blog-post/machine-learning-security-principles-updated)                                                                                 | 8. 模型 - 鲁棒性、抗干扰性, 18. 供应链相关风险, 9. 模型 - 准确性、可靠性（幻觉）, 10. 模型 - 被篡改风险（如模型参数被篡改）                                                                                                                                                                                                                                                                                                                                                                                                                                                  | AI 生命周期, AI 风险来源              |
| Guidelines for Secure AI System Development                                                                                                                                   | 标准指南、技术性文件 | 🌍 multi         | 2023-11-26 00:00:00 | USA CISA, UK NCSC, the Australian Signals Directorate’s Australian Cyber Security Centre (ASD ACSC), the Canadian Centre for Cyber Security (CCCS), the New Zealand National Cyber Security Centre (NCSC-NZ) | [link](https://www.cisa.gov/news-events/alerts/2023/11/26/cisa-and-uk-ncsc-unveil-joint-guidelines-secure-ai-system-development)                                       | 18. 供应链相关风险                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | AI 风险来源                           |
| Secure Software Development Practices for Generative AI and Dual-Use Foundation Models: An SSDF Community Profile                                                             | 标准指南、技术性文件 | 🇺🇸 美国          | 2024-07-26 00:00:00 | NIST                                                                                                                                                                                                         | [link](https://csrc.nist.gov/pubs/sp/800/218/a/final)                                                                                                                  | 10. 模型 - 被篡改风险（如模型参数被篡改）, 8. 模型 - 鲁棒性、抗干扰性, 18. 供应链相关风险                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | AI 生命周期                           |
| Artificial Intelligence Risk Management Framework: Generative Artificial Intelligence Profile                                                                                 | 标准指南、技术性文件 | 🇺🇸 美国          | 2024-07-26 00:00:00 | NIST                                                                                                                                                                                                         | [link](https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence)                                         | 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 16. 生成内容 - 自身不利影响（如个人认知、社会问题、国家问题）                                                                                                                                                                                                                                                                                 | AI 风险来源                           |
| Artificial Intelligence Risk Management Framework (AI RMF 1.0)                                                                                                                | 标准指南、技术性文件 | 🇺🇸 美国          | 2023-01-26 00:00:00 | NIST                                                                                                                                                                                                         | [link](https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-ai-rmf-10)                                                                  | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 9. 模型 - 准确性、可靠性（幻觉）, 8. 模型 - 鲁棒性、抗干扰性, 13. 生成内容 - 数据泄露（包括隐私泄露）                                                                                                                                                                                                                                                                                                                                                                                       | AI 风险来源, AI 生命周期              |
| Reducing Risks Posed by Synthetic Content                                                                                                                                     | 标准指南、技术性文件 | 🇺🇸 美国          | 2024-11-24 00:00:00 | NIST                                                                                                                                                                                                         | [link](https://www.nist.gov/publications/reducing-risks-posed-synthetic-content-overview-technical-approaches-digital-content)                                         | 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 16. 生成内容 - 自身不利影响（如个人认知、社会问题、国家问题）, 3. 训练数据 - 数据标注                                                                                                                                                                                                                                                                                                                                                                                                   | AI 风险来源                           |
| LLM AI Cybersecurity & Governance Checklist                                                                                                                                   | 研究报告             | 🌍 NONE          | 2024-02-19 00:00:00 | OWASP                                                                                                                                                                                                        | [link](https://owasp.org/www-project-top-10-for-large-language-model-applications/llm-top-10-governance-doc/LLM_AI_Security_and_Governance_Checklist-v1.pdf)           | 2. 训练数据 - 违规收集 - 个人信息相关, 5. 训练数据 - 数据泄露                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | AI 风险来源                           |
| The Bletchley Declaration                                                                                                                                                     | 论坛会议             | 🌍 multi         | 2024-11-01 00:00:00 | AI Safety Summit 2023                                                                                                                                                                                        | [link](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration)                                                                     | 10. 模型 - 被篡改风险（如模型参数被篡改）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                                                                                               | AI 风险来源                           |
| Consensus Statement on Red Lines in Artificial Intelligence                                                                                                                   | 论坛会议             | 🌍 multi         | 2024-03-10 00:00:00 | “北京AI安全国际对话”论坛                                                                                                                                                                                     | [link](https://idais-beijing.baai.ac.cn/?lang=zh)                                                                                                                      | 10. 模型 - 被篡改风险（如模型参数被篡改）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 8. 模型 - 鲁棒性、抗干扰性                                                                                                                                                                                                                                                                                                                                                                                                                   | AI 风险来源                           |
| Hiroshima Process International Guiding Principles for Advanced AI system                                                                                                     | 标准指南、技术性文件 | 🌍 multi         | 2023-10-30 00:00:00 | G7                                                                                                                                                                                                           | [link](https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-guiding-principles-advanced-ai-system)                                         | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                     | AI 风险来源                           |
| Hiroshima Process International Code of Conduct for Advanced AI Systems                                                                                                       | 标准指南、技术性文件 | 🌍 multi         | 2023-10-30 00:00:00 | G7                                                                                                                                                                                                           | [link](https://digital-strategy.ec.europa.eu/en/library/hiroshima-process-international-code-conduct-advanced-ai-systems)                                              | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 8. 模型 - 鲁棒性、抗干扰性                                                                                                                                                                                                                                                                                                                                           | AI 风险来源                           |
| Blueprint for an AI Bill of Right                                                                                                                                             | 政策性文件           | 🇺🇸 美国          | 2022-10-04 00:00:00 | OSTP (Office of Science and Technology Policy)                                                                                                                                                               | [link](https://www.whitehouse.gov/ostp/ai-bill-of-rights/)                                                                                                             | 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 2. 训练数据 - 违规收集 - 个人信息相关, 13. 生成内容 - 数据泄露（包括隐私泄露）, 6. 模型 - 可解释性                                                                                                                                                                                                                                                  | AI 生命周期, AI 风险来源              |
| Joint Statement on Enforcement Efforts Against Discrimination and Bias in Automated Systems                                                                                   | 政策性文件           | 🇺🇸 美国          | 2023-04-25 00:00:00 | Consumer Financial Protection Bureau                                                                                                                                                                         | [link](https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/joint-statement-enforcement-efforts-against-discrimination-bias-automated-systems) | 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 9. 模型 - 准确性、可靠性（幻觉）, 7. 模型 - 公平性（算法涉及层面）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 6. 模型 - 可解释性                                                                                                                                                                                                                                                      | AI 生命周期, AI 风险来源              |
| Quality Control Standards for Automated Valuation Models                                                                                                                      | 标准指南、技术性文件 | 🇺🇸 美国          | 2023-06-21 00:00:00 | CFPB, OCC, FRB, FDIC, NCUA, and FHFA                                                                                                                                                                         | [link](https://www.consumerfinance.gov/rules-policy/final-rules/quality-control-standards-for-automated-valuation-models/)                                             | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 9. 模型 - 准确性、可靠性（幻觉）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                       | AI 生命周期, AI 风险来源              |
| Colorado’s Consumer Artificial Intelligence Act (SB 24-205)                                                                                                                   | 法律法规 - 已生效    | 🇺🇸 美国          | 2024-05-17 00:00:00 | Colorado                                                                                                                                                                                                     | [link](https://leg.colorado.gov/bills/sb24-205)                                                                                                                        | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 6. 模型 - 可解释性 , 5. 训练数据 - 数据泄露, 2. 训练数据 - 违规收集 - 个人信息相关, 13. 生成内容 - 数据泄露（包括隐私泄露）                                                                                                                                                                                                                                                                                                                                                    | AI 生命周期, AI 风险来源              |
| Safe and Secure Innovation for Frontier Artificial Intelligence Models Act（CA SB 1047）                                                                                      | 法律法规 - 制定中    | 🇺🇸 美国          | 2024-09-03 00:00:00 | California                                                                                                                                                                                                   | [link](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)                                                                           | 10. 模型 - 被篡改风险（如模型参数被篡改）, 11. 模型 - 缺陷传导（如对有缺陷的模型进行微调，导致问题继续存在）, 8. 模型 - 鲁棒性、抗干扰性, 18. 供应链相关风险, 19. 系统相关风险（api、交互页面等）, 5. 训练数据 - 数据泄露                                                                                                                                                                                                                                                                                                                                                    | AI 生命周期, AI 风险来源              |
| Digital Content Provenance Standards (CA AB 3211)                                                                                                                             | 法律法规 - 已生效    | 🇺🇸 美国          | 2024-08-23 00:00:00 | California                                                                                                                                                                                                   | [link](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=202320240AB3211)                                                                          | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 18. 供应链相关风险, 3. 训练数据 - 数据标注, 6. 模型 - 可解释性                                                                                                                                                                                                                                                                                                                                                              | AI 生命周期                           |
| Artificial Intelligence Security Governance Framework v1                                                                                                                      | 标准指南、技术性文件 | 🇨🇳 中国          | 2024-09-09 00:00:00 | tc 260                                                                                                                                                                                                       | [link](https://www.tc260.org.cn/front/postDetail.html?id=20240909102807)                                                                                               | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 3. 训练数据 - 数据标注, 6. 模型 - 可解释性 , 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 10. 模型 - 被篡改风险（如模型参数被篡改）, 5. 训练数据 - 数据泄露, 17. 算力相关风险, 18. 供应链相关风险, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）                                                            | AI 应用场景, AI 风险来源, AI 生命周期 |
| Seizing the Opportunities of Safe, Secure and Trustworthy Artificial Intelligence Systems for Sustainable Development                                                         | 政策性文件           | 🌍 NONE          | 2024-03-21 00:00:00 | UN                                                                                                                                                                                                           | [link](https://digitallibrary.un.org/record/4043244/?v=pdf)                                                                                                            | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 5. 训练数据 - 数据泄露, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 14. 生成内容 - 模型幻觉, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 6. 模型 - 可解释性 , 7. 模型 - 公平性（算法涉及层面）, 19. 系统相关风险（api、交互页面等）, 17. 算力相关风险                                                                                                                             | AI 生命周期, AI 风险来源              |
| Guidelines on Securing AI Systems                                                                                                                                             | 标准指南、技术性文件 | 🇸🇬 新加坡        | 2024-10-15 00:00:00 | CSA                                                                                                                                                                                                          | [link](https://www.csa.gov.sg/Tips-Resource/publications/2024/guidelines-on-securing-ai)                                                                               | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 7. 模型 - 公平性（算法涉及层面）, 8. 模型 - 鲁棒性、抗干扰性, 9. 模型 - 准确性、可靠性（幻觉）, 10. 模型 - 被篡改风险（如模型参数被篡改）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 16. 生成内容 - 自身不利影响（如个人认知、社会问题、国家问题）, 17. 算力相关风险, 18. 供应链相关风险, 19. 系统相关风险（api、交互页面等） | AI 生命周期                           |
| ICO consultation series on generative AI and data protection                                                                                                                  | 研究报告             | 🇬🇧 英国          | 2024-09-18 00:00:00 | ICO                                                                                                                                                                                                          | [link](https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-series-on-generative-ai-and-data-protection/)                               | 13. 生成内容 - 数据泄露（包括隐私泄露）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 14. 生成内容 - 模型幻觉, 5. 训练数据 - 数据泄露, 6. 模型 - 可解释性 , 7. 模型 - 公平性（算法涉及层面）, 2. 训练数据 - 违规收集 - 个人信息相关                                                                                                                                                                                                                                                                                              | AI 风险来源                           |
| Guidance on AI and data protection                                                                                                                                            | 研究报告             | 🇬🇧 英国          | 2023-03-15 00:00:00 | ICO                                                                                                                                                                                                          | [link](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/)                                | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 5. 训练数据 - 数据泄露, 6. 模型 - 可解释性 , 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 17. 算力相关风险, 18. 供应链相关风险, 19. 系统相关风险（api、交互页面等）                                                                                                | AI 风险来源, AI 生命周期              |
| Discussion paper on GDPR and LLMs                                                                                                                                             | 研究报告             | 🇩🇪 德国          | 2024-07-15 00:00:00 | HmbBfDI                                                                                                                                                                                                      | [link](https://datenschutz-hamburg.de/news/hamburger-thesen-zum-personenbezug-in-large-language-models)                                                                | 2. 训练数据 - 违规收集 - 个人信息相关, 9. 模型 - 准确性、可靠性（幻觉）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                        | AI 风险来源                           |
| Checklist for the use of LLM-based chatbots                                                                                                                                   | 标准指南、技术性文件 | 🇩🇪 德国          | 2023-11-13 00:00:00 | HmbBfDI                                                                                                                                                                                                      | [link](https://datenschutz-hamburg.de/news/checkliste-zum-einsatz-llm-basierter-chatbots)                                                                              | 2. 训练数据 - 违规收集 - 个人信息相关, 13. 生成内容 - 数据泄露（包括隐私泄露）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 19. 系统相关风险（api、交互页面等）, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                              | AI 风险来源                           |
| Opinion 28/2024 on certain data protection aspects related to the processing of personal data in the context of AI models                                                     | 研究报告             | 🇪🇺 欧盟          | 2024-10-28 00:00:00 | EDPB                                                                                                                                                                                                         | [link](https://www.edpb.europa.eu/our-work-tools/our-documents/opinion-board-art-64/opinion-282024-certain-data-protection-aspects_en)                                 | 2. 训练数据 - 违规收集 - 个人信息相关, 5. 训练数据 - 数据泄露, 7. 模型 - 公平性（算法涉及层面）, 8. 模型 - 鲁棒性、抗干扰性, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                    | AI 风险来源                           |
| The Artificial Intelligence and Data Act (AIDA)                                                                                                                               | 法律法规 - 制定中    | 🇨🇦 加拿大        | 2022-06-16 00:00:00 | Minister of Innovation, Science and Industry                                                                                                                                                                 | [link](https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading)                                                                                             | 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 8. 模型 - 鲁棒性、抗干扰性, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 19. 系统相关风险（api、交互页面等）                                                                                                                | AI 生命周期, AI 风险来源              |
| Voluntary  Code of Conduct on the Responsible Development and Management of Advanced  Generative AI Systems                                                                   | 标准指南、技术性文件 | 🇨🇦 加拿大        | 2024-09-01 00:00:00 | nan                                                                                                                                                                                                          | [link](https://ised-isde.canada.ca/site/ised/en/voluntary-code-conduct-responsible-development-and-management-advanced-generative-ai-systems)                          | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 8. 模型 - 鲁棒性、抗干扰性, 9. 模型 - 准确性、可靠性（幻觉）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 10. 模型 - 被篡改风险（如模型参数被篡改）                                                                                                                                                                                                                            | AI 风险来源                           |
| Australia’s AI Ethics Principles                                                                                                                                              | 标准指南、技术性文件 | 🇦🇺 澳大利亚      | 2019-01-01 00:00:00 | Department of Industry, Science and Resources                                                                                                                                                                | [link](https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-principles/australias-ai-ethics-principles)                                  | 13. 生成内容 - 数据泄露（包括隐私泄露）, 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 8. 模型 - 鲁棒性、抗干扰性, 6. 模型 - 可解释性                                                                                                                                                                                                                                                                                                                                                                                                                  | AI 风险来源                           |
| Safe and Responsible  AI in Australia (Discussion paper)                                                                                                                      | 研究报告             | 🇦🇺 澳大利亚      | 2023-06-01 00:00:00 | Department of Industry, Science and Resources                                                                                                                                                                | [link](https://consult.industry.gov.au/supporting-responsible-ai)                                                                                                      | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 14. 生成内容 - 模型幻觉, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 2. 训练数据 - 违规收集 - 个人信息相关                                                                                                                                                                                                                                   | AI 风险来源                           |
| Safe and responsible Al in Australia consultation - Australian Government's interim response                                                                                  | 研究报告             | 🇦🇺 澳大利亚      | 2024-01-17 00:00:00 | Department of Industry, Science and Resources                                                                                                                                                                | [link](https://consult.industry.gov.au/supporting-responsible-ai)                                                                                                      | 1. 训练数据 - 违规收集 - 知产相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 14. 生成内容 - 模型幻觉, 16. 生成内容 - 自身不利影响（如个人认知、社会问题、国家问题）                                                                                                                                                                                                      | AI 风险来源                           |
| Select Committee on  Adopting                                                                                                                                                 | 法律法规 - 已生效    | 🇦🇺 澳大利亚      | 2024-03-26 00:00:00 | nan                                                                                                                                                                                                          | [link](https://www.aph.gov.au/Parliamentary_Business/Committees/Senate/Adopting_Artificial_Intelligence_AI/AdoptingAI)                                                 | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 17. 算力相关风险, 19. 系统相关风险（api、交互页面等）                                                                                       | AI 生命周期, AI 应用场景              |
| Artificial Intelligence                                                                                                                                                       |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| National framework for the assurance of  artificial intelligence in government                                                                                                | 标准指南、技术性文件 | 🇦🇺 澳大利亚      | 2024-06-21 00:00:00 | Australian, state and territory governments                                                                                                                                                                  | [link](https://www.finance.gov.au/sites/default/files/2024-06/National-framework-for-the-assurance-of-AI-in-government.pdf)                                            | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 9. 模型 - 准确性、可靠性（幻觉）, 6. 模型 - 可解释性 , 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 18. 供应链相关风险                                                                                                                                                                                                                                                                                                                                               | AI 生命周期                           |
| AI Guidelines for Business v1                                                                                                                                                 | 标准指南、技术性文件 | 🇯🇵 日本          | 2024-04-19 00:00:00 | METI, Ministry of Economy, Trade and Industry                                                                                                                                                                | [link](https://www.meti.go.jp/english/press/2024/0419_002.html)                                                                                                        | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 19. 系统相关风险（api、交互页面等）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                  | AI 生命周期                           |
| Methodology for the Risk and Impact Assessment of Artificial Intelligence Systems from the Point of View of Human Rights, Democracy and the Rule of Law (HUDERIA Methodology) | 标准指南、技术性文件 | 🇪🇺 欧盟          | 2024-09-28 00:00:00 | CAI, Committee on Artificial Intelligence                                                                                                                                                                    | [link](https://www.coe.int/en/web/artificial-intelligence/huderia-risk-and-impact-assessment-of-ai-systems)                                                            | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 9. 模型 - 准确性、可靠性（幻觉）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                              | AI 生命周期                           |
|                                                                                                                                                                               |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
|                                                                                                                                                                               |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
|                                                                                                                                                                               |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| 用德语将"HUDERIA METHODOLOGY"改写成首字母大写的表达                                                                                                                           |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| 除了首字母大写，还有哪些常见的改写文本格式？                                                                                                                                  |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| 怎样确保改写后的文本准确传达原意？                                                                                                                                            |                      |                  |                     |                                                                                                                                                                                                              |                                                                                                                                                                        |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                       |
| Open letter to UK online service providers regarding Generative AI and chatbots                                                                                               | 标准指南、技术性文件 | 🇬🇧 英国          | 2024-11-08 00:00:00 | OFCOM                                                                                                                                                                                                        | [link](https://www.ofcom.org.uk/online-safety/illegal-and-harmful-content/open-letter-to-uk-online-service-providers-regarding-generative-ai-and-chatbots/)            | 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                                                                                                                                                 | AI 应用场景                           |
| Introduction to AI Assurance                                                                                                                                                  | 标准指南、技术性文件 | 🇬🇧 英国          | 2024-02-12 00:00:00 | DSIT, Department for Science, Innovation and Technology                                                                                                                                                      | [link](https://www.gov.uk/government/publications/introduction-to-ai-assurance)                                                                                        | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 9. 模型 - 准确性、可靠性（幻觉）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 2. 训练数据 - 违规收集 - 个人信息相关                                                                                                                                                                                                                                                                      | AI 生命周期, AI 应用场景              |
| Guidance for using the AI Management Essentials tool                                                                                                                          | 标准指南、技术性文件 | 🇬🇧 英国          | 2024-11-06 00:00:00 | DSIT                                                                                                                                                                                                         | [link](https://www.gov.uk/government/consultations/ai-management-essentials-tool/guidance-for-using-the-ai-management-essentials-tool)                                 | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 9. 模型 - 准确性、可靠性（幻觉）, 5. 训练数据 - 数据泄露, 13. 生成内容 - 数据泄露（包括隐私泄露）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）                                                                                                                                                                                                                                                                                     | AI 生命周期                           |
| Compliance of products with embedded artificial intelligence                                                                                                                  | 标准指南、技术性文件 | 🌍 NONE          | 2024-11-04 00:00:00 | UNECE，联合国欧洲经济委员会                                                                                                                                                                                  | [link](https://unece.org/trade/publications/ece_trade_486)                                                                                                             | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 9. 模型 - 准确性、可靠性（幻觉）, 8. 模型 - 鲁棒性、抗干扰性, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 18. 供应链相关风险                                                                                                                                                                                                                                                                                                                                        | AI 应用场景                           |
| Model AI Governance Framework for Generative AI                                                                                                                               | 标准指南、技术性文件 | 🇸🇬 新加坡        | 2024-05-24 00:00:00 | IMDA                                                                                                                                                                                                         | [link](https://aiverifyfoundation.sg/resources/mgf-gen-ai/)                                                                                                            | 1. 训练数据 - 违规收集 - 知产相关, 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 6. 模型 - 可解释性 , 9. 模型 - 准确性、可靠性（幻觉）, 10. 模型 - 被篡改风险（如模型参数被篡改）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 14. 生成内容 - 模型幻觉, 18. 供应链相关风险                                                                                                                                                                                                 | AI 生命周期                           |
| AI and cyber security: what you need to know                                                                                                                                  | 研究报告             | 🇬🇧 英国          | 2024-02-13 00:00:00 | NCSC                                                                                                                                                                                                         | [link](https://www.ncsc.gov.uk/guidance/ai-and-cyber-security-what-you-need-to-know)                                                                                   | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 14. 生成内容 - 模型幻觉, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）                                                                                                                                                                                                                                                                          | AI 风险来源                           |
| Machine learning principles                                                                                                                                                   | 标准指南、技术性文件 | 🇬🇧 英国          | 2024-05-22 00:00:00 | NCSC                                                                                                                                                                                                         | [link](https://www.ncsc.gov.uk/collection/machine-learning-principles)                                                                                                 | 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 8. 模型 - 鲁棒性、抗干扰性, 10. 模型 - 被篡改风险（如模型参数被篡改）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 18. 供应链相关风险, 19. 系统相关风险（api、交互页面等）                                                                                                                                                                                                                                                 | AI 生命周期                           |
| The Artificial Intelligence and Data Act (AIDA)  – Companion document                                                                                                         | 标准指南、技术性文件 | 🇨🇦 加拿大        | 2023-03-13 00:00:00 | Minister of Innovation, Science and Industry                                                                                                                                                                 | [link](https://ised-isde.canada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-companion-document)                                      | 2. 训练数据 - 违规收集 - 个人信息相关, 4. 训练数据 - 内容不当（歧视偏见、不具有多样性、被投毒等）, 7. 模型 - 公平性（算法涉及层面）, 8. 模型 - 鲁棒性、抗干扰性, 9. 模型 - 准确性、可靠性（幻觉）, 12. 生成内容 - 内容安全风险（如歧视、偏见、不符合伦理道德、危害社会公共利益、国家安全）, 13. 生成内容 - 数据泄露（包括隐私泄露）, 15. 生成内容 - 不当使用导致风险（各种恶意攻击、各种将AI生成结果用户非法活动的行为）, 19. 系统相关风险（api、交互页面等）                                                                                                                | AI 生命周期, AI 风险来源              |
| Companion Guide on Securing AI Systems                                                                                                                                        | 标准指南、技术性文件 | 🇸🇬 新加坡        | 2024-10-15 00:00:00 | CSA                                                                                                                                                                                                          | [link](https://www.csa.gov.sg/Tips-Resource/publications/2024/guidelines-on-securing-ai)                                                                               | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | nan                                   |
| Online Safety Act                                                                                                                                                             | 法律法规 - 已生效    | 🇬🇧 英国          | 2023-10-26 00:00:00 | OFCOM                                                                                                                                                                                                        | [link](https://www.legislation.gov.uk/ukpga/2023/50/section/1/enacted)                                                                                                 | nan                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | nan                                   |